{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4bfb0fa",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# A/B Testing Deployment with Amazon SageMaker\n",
    "\n",
    "This Jupyter notebook guides you through implementing an A/B testing deployment strategy for machine learning models using Amazon SageMaker.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- An AWS account with SageMaker access\n",
    "- Basic understanding of Python and machine learning concepts\n",
    "\n",
    "\n",
    "## Lab Overview\n",
    "\n",
    "In this lab, you will:\n",
    "\n",
    "1. Set up a SageMaker environment\n",
    "2. Prepare a small dataset and train two simple models\n",
    "3. Deploy models using A/B testing\n",
    "4. Evaluate model performance\n",
    "5. Clean up resources\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c848aafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "session = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89045525",
   "metadata": {},
   "source": [
    "## 2. Data Preparation and Model Training\n",
    "\n",
    "We'll use a small subset of the iris dataset for quick training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a72b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data[:100], iris.target[:100]  # Using only 100 samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = pd.DataFrame(X_train, columns=iris.feature_names)\n",
    "train_data['target'] = y_train\n",
    "test_data = pd.DataFrame(X_test, columns=iris.feature_names)\n",
    "test_data['target'] = y_test\n",
    "\n",
    "train_data.to_csv('train.csv', index=False, header=False)\n",
    "test_data.to_csv('test.csv', index=False, header=False)\n",
    "\n",
    "s3_input_train = session.upload_data(path='train.csv', key_prefix='sagemaker/iris/train')\n",
    "s3_input_test = session.upload_data(path='test.csv', key_prefix='sagemaker/iris/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e034b1fd",
   "metadata": {},
   "source": [
    "Now, let's train two simple models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94eaf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train_model_a.py\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import argparse, joblib, os\n",
    "import numpy as np\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--n-estimators', type=int, default=10)\n",
    "parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "train_data = np.loadtxt(os.path.join(args.train, 'train.csv'), delimiter=',')\n",
    "X = train_data[:, :-1]\n",
    "y = train_data[:, -1]\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=args.n_estimators)\n",
    "model.fit(X, y)\n",
    "\n",
    "joblib.dump(model, os.path.join(args.model_dir, 'model.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3e11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train_model_b.py\n",
    "from sklearn.svm import SVC\n",
    "import argparse, joblib, os\n",
    "import numpy as np\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--C', type=float, default=1.0)\n",
    "parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "train_data = np.loadtxt(os.path.join(args.train, 'train.csv'), delimiter=',')\n",
    "X = train_data[:, :-1]\n",
    "y = train_data[:, -1]\n",
    "\n",
    "model = SVC(C=args.C)\n",
    "model.fit(X, y)\n",
    "\n",
    "joblib.dump(model, os.path.join(args.model_dir, 'model.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837869b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model A with Spot Instances\n",
    "sklearn_estimator_a = SKLearn(\n",
    "    entry_point='train_model_a.py',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',  #choose one that is available at your region\n",
    "    framework_version='0.23-1',\n",
    "    hyperparameters={'n-estimators': 10},\n",
    "    use_spot_instances=True,\n",
    "    max_run=3600,  # 1 hour maximum runtime\n",
    "    max_wait=3605  # Maximum time to wait for spot instances (slightly longer than max_run)\n",
    ")\n",
    "\n",
    "sklearn_estimator_a.fit({'train': s3_input_train})\n",
    "\n",
    "# Train Model B with Spot Instances\n",
    "sklearn_estimator_b = SKLearn(\n",
    "    entry_point='train_model_b.py',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',  #choose one that is available at your region\n",
    "    framework_version='0.23-1',\n",
    "    hyperparameters={'C': 1.0},\n",
    "    use_spot_instances=True,\n",
    "    max_run=3600,  # 1 hour maximum runtime\n",
    "    max_wait=3605  # Maximum time to wait for spot instances (slightly longer than max_run)\n",
    ")\n",
    "\n",
    "sklearn_estimator_b.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db92815",
   "metadata": {},
   "source": [
    "## 3. A/B Testing Deployment\n",
    "\n",
    "Now, let's deploy both models using A/B testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780eac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import production_variant\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from datetime import datetime\n",
    "\n",
    "# Explicitly create SageMaker Models from trained estimators\n",
    "model_a = sklearn_estimator_a.create_model()\n",
    "model_b = sklearn_estimator_b.create_model()\n",
    "\n",
    "# Explicitly register the models with unique names\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "model_a.name = f\"model-a-{timestamp}\"\n",
    "model_b.name = f\"model-b-{timestamp}\"\n",
    "\n",
    "model_a._create_sagemaker_model(instance_type='ml.m5.large', accelerator_type=None)\n",
    "model_b._create_sagemaker_model(instance_type='ml.m5.large', accelerator_type=None)\n",
    "\n",
    "# Create production variants for A/B testing\n",
    "variant1 = production_variant(\n",
    "    model_name=model_a.name,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    initial_instance_count=1,\n",
    "    variant_name='ModelA',\n",
    "    initial_weight=50\n",
    ")\n",
    "\n",
    "variant2 = production_variant(\n",
    "    model_name=model_b.name,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    initial_instance_count=1,\n",
    "    variant_name='ModelB',\n",
    "    initial_weight=50\n",
    ")\n",
    "\n",
    "endpoint_name = 'iris-ab-test-endpoint'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86699c60-c36c-442c-be15-7aa917a4b844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the endpoint with the variants\n",
    "session.endpoint_from_production_variants(\n",
    "    name=endpoint_name,\n",
    "    production_variants=[variant1, variant2]\n",
    ")\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=session,\n",
    "    serializer=CSVSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56476b23",
   "metadata": {},
   "source": [
    "## 4. Evaluate Model Performance\n",
    "\n",
    "Let's test our A/B deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904f1a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "results = {'ModelA': 0, 'ModelB': 0}\n",
    "\n",
    "for _ in range(50):\n",
    "    response = predictor.predict(X_test[0].tolist())\n",
    "    variant_used = response['ResponseMetadata']['HTTPHeaders']['x-amzn-sagemaker-production-variant']\n",
    "    results[variant_used] += 1\n",
    "    time.sleep(0.1)  # To avoid throttling\n",
    "\n",
    "print(\"Model A was used:\", results['ModelA'], \"times\")\n",
    "print(\"Model B was used:\", results['ModelB'], \"times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29907413",
   "metadata": {},
   "source": [
    "## 5. Clean Up Resources\n",
    "\n",
    "Always remember to clean up your resources to avoid unnecessary charges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afbd048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Up Resources - IMPORTANT to avoid ongoing charges\n",
    "\n",
    "# 1. Delete the endpoint\n",
    "print(\"Cleaning up resources...\")\n",
    "try:\n",
    "    predictor.delete_endpoint()\n",
    "    print(\"Endpoint deleted successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting endpoint: {e}\")\n",
    "\n",
    "# 2. Delete all endpoint configurations\n",
    "sm_client = boto3.client('sagemaker')\n",
    "try:\n",
    "    endpoint_configs = sm_client.list_endpoint_configs()\n",
    "    for config in endpoint_configs['EndpointConfigs']:\n",
    "        config_name = config['EndpointConfigName']\n",
    "        if endpoint_name in config_name:\n",
    "            print(f\"Deleting endpoint configuration: {config_name}\")\n",
    "            sm_client.delete_endpoint_config(EndpointConfigName=config_name)\n",
    "    print(\"All endpoint configurations deleted\")\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting endpoint configurations: {e}\")\n",
    "\n",
    "# 3. Delete all models\n",
    "try:\n",
    "    models = sm_client.list_models()\n",
    "    for model in models['Models']:\n",
    "        model_name = model['ModelName']\n",
    "        if model_a.name in model_name or model_b.name in model_name:\n",
    "            print(f\"Deleting model: {model_name}\")\n",
    "            sm_client.delete_model(ModelName=model_name)\n",
    "    print(\"All models deleted\")\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting models: {e}\")\n",
    "\n",
    "print(\"All resources have been cleaned up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ec0ba3",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this lab, you learned how to implement A/B testing deployment for machine learning models using Amazon SageMaker. You created two simple models, deployed them using A/B testing, and evaluated their usage. Remember to always clean up your resources after completing your experiments.\n",
    "\n",
    "## Common Mistakes and Best Practices\n",
    "\n",
    "- Ensure you have sufficient permissions to create and manage SageMaker resources.\n",
    "- Always use the smallest instance type that can handle your workload to minimize costs.\n",
    "- Remember to delete endpoints and models after you're done to avoid ongoing charges.\n",
    "- When implementing A/B testing in production, consider using more sophisticated metrics and longer evaluation periods.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
